{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e75879",
   "metadata": {},
   "source": [
    "# Visualizing Tokens\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/labmlai/inspectus/blob/main/notebooks/token_viz.ipynb)\n",
    "\n",
    "This Jupyter notebook demonstrates how to use the Inspectus library to visualize tokens and any related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8687941",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install inspectus\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bb6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, GPT2LMHeadModel\n",
    "import inspectus\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3bc76c",
   "metadata": {},
   "source": [
    "Following cell sets up a GPT-2 model from Huggingface's Transformers library. It initializes the tokenizer and model configuration, then creates the GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97891fb",
   "metadata": {},
   "source": [
    "This cell takes a sentence and tokenizes it using the previously initialized tokenizer. The tokenized output is then used to create input IDs for the model and a list of tokens. It uses the 'offset_mapping' attribute returned by the tokenizer to slice the original text into individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa96f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32. The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.'\n",
    "tokenized = tokenizer(\n",
    "    text,\n",
    "    return_tensors='pt',\n",
    "    return_offsets_mapping=True\n",
    ")\n",
    "input_ids = tokenized['input_ids']\n",
    "\n",
    "tokens = [text[s: e] for s, e in tokenized['offset_mapping'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    res = model(input_ids=input_ids.to(model.device), output_attentions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c0f23",
   "metadata": {},
   "source": [
    "Following cell gets the top 5 predictions for each token in the given text along with the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04275507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import nll_loss\n",
    "\n",
    "logits = res['logits']\n",
    "losses = []\n",
    "entropies = []\n",
    "token_info = []\n",
    "for i in range(len(tokens)):\n",
    "    loss = nll_loss(logits[0, i], input_ids[0, i])\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    entropy = -torch.sum(torch.nn.functional.softmax(logits[0, i]) * torch.nn.functional.log_softmax(logits[0, i]))\n",
    "    entropies.append(entropy.item())\n",
    "\n",
    "    pred_token_indices = torch.argsort(logits[0, i])[:5]\n",
    "    pred_tokens = [tokenizer.decode([idx]) for idx in pred_token_indices]\n",
    "    token_info.append(f\"pred 1: {pred_tokens[0]}\\npred 2: {pred_tokens[1]}\\npred 3: {pred_tokens[2]}\\npred 4: {pred_tokens[3]}\\npred 5: {pred_tokens[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd638aa",
   "metadata": {},
   "source": [
    "The `inspectus.tokens` function visualizes tokens using their losses. Hover on to a token to view aditional info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspectus.tokens(tokens, {\"loss\": losses, \"entropy\": entropies}, token_info=token_info, theme=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27eef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
